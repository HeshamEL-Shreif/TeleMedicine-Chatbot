# ğŸ§  TeleMedicine Chatbot â€“ Backend (FastAPI + LangGraph)

This repository combines two major components:

### ğŸ“Œ 1. Preprocessing & OCR Pipeline  
A script that automates the scraping and transformation of public Arabic and English medical documents into structured PDF files:
- ğŸŒ Scrapes images from a public Google Sites portal for patient education
- ğŸ§  Extracts Arabic text using a Vision-Language Qwen2 model
- ğŸ”  Extracts English text using Tesseract OCR
- ğŸ—ƒ Merges extracted text and saves them as `.txt` files
- ğŸ§¾ Converts all text into **properly aligned Arabic-friendly PDFs** using ReportLab

### ğŸš€ 2. Multilingual AI Chatbot Backend  
A FastAPI server that supports Arabic-English medical queries using Retrieval-Augmented Generation (RAG) with Groqâ€™s LLaMA 4 model, LangGraph agents, and web search tools.

---

## ğŸ©º Features

- ğŸ” Medical QA with Retrieval-Augmented Generation (RAG)  
- ğŸŒ Arabic & English support with dynamic language detection  
- ğŸ“‘ Synthetic paragraph generation for semantic document search  
- ğŸ›  LangGraph agent for smart tool use & reasoning  
- ğŸ“š Persistent document storage in Chroma vector DB  
- ğŸŒ Web augmentation using Tavily API  
- ğŸš€ FastAPI server with an intuitive REST endpoint  
- ğŸ³ Docker-ready for fast deployment  
- ğŸ–¼ Preprocessing pipeline that scrapes medical image content and prepares structured PDF datasets  

---

## ğŸ—‚ Project Structure

```bash
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ downloaded_images_Ar/       # Arabic scraped images and extracted text
â”‚   â”œâ”€â”€ downloaded_images_En/       # English scraped images and extracted text
â”‚   â”œâ”€â”€ Amiri-Regular.ttf           # Arabic-capable font for PDF generation
â”‚   â””â”€â”€ scraper_ocr_pipeline.py     # Google Sites scraper + OCR extractor + PDF builder
â”œâ”€â”€ db/                            # Vector DB logic (Chroma)
â”‚   â””â”€â”€ vector_db.py
â”œâ”€â”€ documents/                    # Auto-generated PDFs from extracted medical content
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ utils.py                  # LLM and search tool logic
â”œâ”€â”€ retrieve.py                   # Generates synthetic Arabic documents
â”œâ”€â”€ agent.py                      # LangGraph agent workflow
â”œâ”€â”€ main.py                       # FastAPI app with /query endpoint
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ğŸ§  LLM & Tools

| Component        | Model/Tool                                                                 |
|------------------|-----------------------------------------------------------------------------|
| LLM              | `meta-llama/llama-4-scout-17b-16e-instruct` via Groq API                    |
| Arabic OCR       | `NAMAA-Space/Qari-OCR-0.1-VL-2B-Instruct`                                   |
| Embeddings       | `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`               |
| English OCR      | Tesseract (`pytesseract`)                                                   |
| Search API       | Tavily                                                                       |
| RAG Agent        | LangGraph                                                                   |

---

## ğŸ§ª Example API Call

**Endpoint:** `POST /query`  
**Request:**
```json
{
  "query": "Ù…Ø§ Ù‡Ùˆ Ø¯ÙˆØ§Ø¡ Ø§Ù„Ø¯Ø§ÙƒØªÙˆÙ†ØŸ"
}
```
**Response:**
```json
{
  "answer": "Ø§Ù„Ø¯Ø§ÙƒØªÙˆÙ† (Ø³Ø¨ÙŠØ±ÙˆÙ†ÙˆÙ„Ø§ÙƒØªÙˆÙ†) Ù‡Ùˆ Ø¯ÙˆØ§Ø¡ Ù…Ø¯Ø± Ù„Ù„Ø¨ÙˆÙ„ ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙˆØªØ§Ø³ÙŠÙˆÙ… ÙˆÙŠØ³ØªØ®Ø¯Ù… Ù„Ø¹Ù„Ø§Ø¬ Ø§Ø­ØªØ¨Ø§Ø³ Ø§Ù„Ø³ÙˆØ§Ø¦Ù„ Ø§Ù„Ù†Ø§ØªØ¬ Ø¹Ù† Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨ ÙˆØ§Ù„ÙƒØ¨Ø¯ ÙˆØ§Ù„ÙƒÙ„Ù‰..."
}
```

---

## ğŸ§° Setup Instructions

### 1. Clone the Repo
```bash
git clone https://github.com/yourusername/telemedicine-chatbot-backend.git
cd telemedicine-chatbot-backend
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Configure API Keys in `.env`
```
TAVILY_API_KEY=your_api_key_here
HUGGINGFACEHUB_API_TOKEN=your_api_key_here
GROQ_API_KEY=your_api_key_here
```

---

## ğŸ§ª Run the Backend API

```bash
uvicorn main:app --reload
```
Access docs at: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ–¼ Run the Scraper + OCR Pipeline

The pipeline is already integrated into `scraper_ocr_pipeline.py`.

To run it:
```bash
python ./data/scraper_ocr_pipeline.py
```

This will:
- Scrape the main Google Sites medical portal
- Save Arabic & English images under respective folders
- Extract and save `.txt` files from images
- Generate properly formatted PDFs into the `documents/` folder

---

## ğŸ³ Docker Usage

### Build the Image
```bash
docker build -t telemedicine-backend .
```

### Run the Container
```bash
docker run -p 8000:8000 telemedicine-backend
```

---

## ğŸ§  How It Works
1.	User query is received.
2.	Query is language detected (Arabic or English).
3.	A synthetic paragraph is generated using LLM to simulate an answer-containing doc.
4.	Similarity search runs on that paragraph against internal medical vector DB.
5.	Web search snippets are fetched via Tavily (if relevant).
6.	LangGraph agent uses tools + context to generate a final answer.
7.	Final answer is returned in the userâ€™s language, avoiding direct quoting.

---

## ğŸ§  Prompt Logic Highlights
- Responds only with medical facts
- Ignores or filters non-medical questions
- Detects and replies in the userâ€™s language
- Prefers internal documents, then supplements with web content
- Avoids hallucinations and general-purpose LLM errors